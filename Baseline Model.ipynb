{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faustotnc/.pyenv/versions/3.8.5/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "import unidecode\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Prevent kernel from dying\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the data\n",
    "labeledPfd = pd.read_csv(\"./datasets/LabeledPoetryFoundationPoems.csv\")\n",
    "\n",
    "\n",
    "# Filters the poems by category\n",
    "def get_poems_by_category(category):\n",
    "    data = []\n",
    "    for poem, emotion in zip(labeledPfd[\"poem\"], labeledPfd[\"emotion\"]):\n",
    "        if emotion == category:\n",
    "            data.append(poem)\n",
    "    return data\n",
    "\n",
    "\n",
    "# The available poem categories\n",
    "all_categories = [\"joy\", \"trust\", \"sadness\", \"anticipation\", \"fear\", \"anger\", \"disgust\", \"surprise\"]\n",
    "# The number of categories we have\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "# Gets the poems in each category\n",
    "poems = {\n",
    "    \"joy\": get_poems_by_category(\"joy\"),\n",
    "    \"trust\": get_poems_by_category(\"trust\"),\n",
    "    \"sadness\": get_poems_by_category(\"sadness\"),\n",
    "    \"anticipation\": get_poems_by_category(\"anticipation\"),\n",
    "    \"fear\": get_poems_by_category(\"fear\"),\n",
    "    \"anger\": get_poems_by_category(\"anger\"),\n",
    "    \"disgust\": get_poems_by_category(\"disgust\"),\n",
    "    \"surprise\": get_poems_by_category(\"surprise\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42262"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training with only 500 poems.\n",
    "# When trying to train with the entrie dataset (~4000 poems)\n",
    "# the kernel dies before completing the first epoch.\n",
    "text = list(poems[\"joy\"][:200])\n",
    "\n",
    "def joinStrings(text):\n",
    "    return ' '.join(string for string in text)\n",
    "text = joinStrings(text)\n",
    "len(text.split()) # Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = set(nltk.corpus.stopwords.words('english'))\n",
    "# exclude = set(string.punctuation) \n",
    "# lemma = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "# def clean(doc):\n",
    "#         stop_free = \" \".join([i for i in doc.split() if i not in stop])\n",
    "#         punc_free = \"\".join(ch for ch in stop_free if ch not in exclude)\n",
    "#         normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "#         return normalized\n",
    "\n",
    "clean_data = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Invisible', 'fish'], 'swim'), (['fish', 'swim'], 'this'), (['swim', 'this'], 'ghost')]\n"
     ]
    }
   ],
   "source": [
    "# Generates trigram word embeddings\n",
    "# with the data. For the sentence:\n",
    "# \"I party with my friends on the weekedns\"\n",
    "# \"with\", and \"my\" will be the context for\n",
    "# the word \"friends\". An example is printed bellow\n",
    "embeddings = [ ([trigram[0], trigram[1]], trigram[2]) for trigram in ngrams(clean_data, 4)]\n",
    "chunk_len = len(embeddings)\n",
    "print(embeddings[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the vocabulary\n",
    "vocab = set(clean_data)\n",
    "voc_len = len(vocab)\n",
    "\n",
    "# Encodes the position of each word in the vocabulary\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the input and target vectors\n",
    "inp, tar = ([], [])\n",
    "for context, target in embeddings:\n",
    "    context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "    inp.append(context_idxs)\n",
    "    targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "    tar.append(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        # We are using the GRU method to train the model\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for c in range(chunk_len):\n",
    "        print(c, \"out of\", chunk_len, end=\"\\r\")\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c])\n",
    "\n",
    "    print(\"Performing back-propagation...\", end=\"\\r\")\n",
    "    \n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3m 23s (1 5%) 9.0933]ation...\n",
      "[6m 41s (2 10%) 8.8929]tion...\n",
      "[9m 56s (3 15%) 7.9436]tion...\n",
      "[13m 19s (4 20%) 7.2803]ion...\n",
      "[16m 44s (5 25%) 6.9546]ion...\n",
      "[20m 9s (6 30%) 6.8849]tion...out of 48811 48811\n",
      "[23m 25s (7 35%) 6.9546]ion... 48811\n",
      "[26m 41s (8 40%) 6.9420]ion...\n",
      "[29m 56s (9 45%) 6.8750]ion...\n",
      "[55m 24s (10 50%) 6.8170]on...\n",
      "[58m 45s (11 55%) 6.7815]on...\n",
      "[62m 5s (12 60%) 6.7528]ion...\n",
      "[65m 30s (13 65%) 6.7262]on...\n",
      "[68m 52s (14 70%) 6.6906]on...\n",
      "[72m 12s (15 75%) 6.6476]on...\n",
      "[75m 33s (16 80%) 6.6060]on...\n",
      "[78m 51s (17 85%) 6.5640]on...\n",
      "[82m 9s (18 90%) 6.5188]ion...\n",
      "[85m 39s (19 95%) 6.4723]on... 48811\n",
      "[88m 54s (20 100%) 6.4249]n...\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "print_every = 1\n",
    "plot_every = 1\n",
    "hidden_size = 120 # 120 nodes on each hidden layer \n",
    "n_layers = 2 # two hidden layers\n",
    "lr = 0.01 # learning rate\n",
    "\n",
    "decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_execution_time_\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    start = time.time()\n",
    "    \n",
    "    loss = train(inp, tar)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1489d1e80>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prime_str='this love', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long)\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this love apocalypse inception hissing midnightâ€”the his voices shuffle t I summer . you on the morning the dreamers much on you magpies touch scan s eventual calling shadows centenary known in We line ! of members red wounds strong , roof-top , in those gown up all the it places to moaned 58 , ! , with The is his and . off then , the toothed spangled Like the . leaves sends '' It did It Dawn-rose your future abusing Of , the eyes a . It kut all Simple buy that girl . The love . though . be\n"
     ]
    }
   ],
   "source": [
    "generated_poem = predict(prime_str='this love', predict_len=100, temperature=1)\n",
    "\n",
    "print(generated_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
