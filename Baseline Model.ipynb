{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faustotnc/.pyenv/versions/3.8.5/lib/python3.8/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "import unidecode\n",
    "import time, math\n",
    "import random\n",
    "import torch\n",
    "\n",
    "# Used by the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Prevent kernel from dying\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the data\n",
    "labeledPfd = pd.read_csv(\"./datasets/LabeledPoetryFoundationPoems.csv\")\n",
    "\n",
    "\n",
    "# Filters the poems by category\n",
    "def get_poems_by_category(category):\n",
    "    data = []\n",
    "    for poem, emotion in zip(labeledPfd[\"poem\"], labeledPfd[\"emotion\"]):\n",
    "        if emotion == category:\n",
    "            data.append(poem)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Gets the poems in each category\n",
    "poems = {\n",
    "    \"joy\": get_poems_by_category(\"joy\"),\n",
    "    \"trust\": get_poems_by_category(\"trust\"),\n",
    "    \"sadness\": get_poems_by_category(\"sadness\"),\n",
    "    \"anticipation\": get_poems_by_category(\"anticipation\"),\n",
    "    \"fear\": get_poems_by_category(\"fear\"),\n",
    "    \"anger\": get_poems_by_category(\"anger\"),\n",
    "    \"disgust\": get_poems_by_category(\"disgust\"),\n",
    "    \"surprise\": get_poems_by_category(\"surprise\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 23487\n",
      "['Invisible', 'fish', 'swim', 'this', 'ghost', 'ocean', 'now', 'described', 'by', 'waves']\n",
      "[(['Invisible', 'fish'], 'swim'), (['fish', 'swim'], 'this'), (['swim', 'this'], 'ghost')]\n"
     ]
    }
   ],
   "source": [
    "# Training with only 100 poems.\n",
    "# When trying to train with the entrie dataset (~4000 poems)\n",
    "# the kernel dies before completing the first epoch.\n",
    "text = list(poems[\"joy\"][:100])\n",
    "\n",
    "def joinStrings(text):\n",
    "    return '\\n'.join(string for string in text)\n",
    "text = joinStrings(text)\n",
    "\n",
    "# Clean the data\n",
    "# valid_chars = string.ascii_letters + \" ,.\\\"\\n\"\n",
    "clean_data = [word for word in nltk.word_tokenize(text)]\n",
    "print(\"Number of tokens:\", len(clean_data)) # Number of tokens\n",
    "print(clean_data[:10])\n",
    "\n",
    "# Extracts the vocabulary\n",
    "vocab = set(clean_data)\n",
    "voc_len = len(vocab)\n",
    "\n",
    "# Encodes the position of each word in the vocabulary\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "# Generates trigram word embeddings\n",
    "# with the data. For the sentence:\n",
    "# \"I party with my friends on the weekends\"\n",
    "# \"with\", and \"my\" will be the context for\n",
    "# the word \"friends\". An example is printed bellow\n",
    "embeddings = [ ([trigram[0], trigram[1]], trigram[2]) for trigram in ngrams(clean_data, 3)]\n",
    "num_embeddings = len(embeddings)\n",
    "print(embeddings[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Input-Output Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the input and target vectors\n",
    "inp, tar = ([], [])\n",
    "for context, target in embeddings:\n",
    "    # 2dim tensor with the positions of the context letters\n",
    "    context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "    inp.append(context_idxs)\n",
    "    \n",
    "    # 1dim tensor with the position of the target letter\n",
    "    targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "    tar.append(targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Recurrent Neural Network (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        # We are using the GRU method to train the model\n",
    "        self.gru = nn.GRU(\n",
    "            hidden_size * 2,\n",
    "            hidden_size,\n",
    "            n_layers,\n",
    "            batch_first = True, # x: (num_embeddings, context_size, input_size)\n",
    "            bidirectional = False\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_vect, hidden):\n",
    "        input_vect = self.encoder(input_vect.view(1, -1)) # flattens the input vector\n",
    "        output, hidden = self.gru(input_vect.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "print_every = 1\n",
    "plot_every = 1\n",
    "hidden_size = 120 # 120 nodes on each hidden layer \n",
    "n_layers = 2 # two hidden layers\n",
    "lr = 0.01 # learning rate\n",
    "\n",
    "model = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "model_optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Trainer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model with the data for\n",
    "# the equivalent of 1 epoch\n",
    "def train(inp, target):\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    # Initializes the gradients and the loss\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    # Trains the neural network over all\n",
    "    # the character embeddings\n",
    "    for i in range(num_embeddings):\n",
    "        # Prints the progress every 1000th embedding\n",
    "        if (i % 1000 == 0):\n",
    "            print(i, \"out of\", num_embeddings, end=\"\\r\")\n",
    "        \n",
    "        # The model taken in a context tensor, and\n",
    "        # the previous hidden state to predict an\n",
    "        # output, and compute a new hidden state\n",
    "        output, hidden = model.forward(inp[i], hidden)\n",
    "        \n",
    "        # The loss is computed using the predicted output\n",
    "        # and the target (expected output)\n",
    "        loss += criterion(output, target[i])\n",
    "\n",
    "    # Propagates the loss backwards\n",
    "    # through the network\n",
    "    print(\"Performing back-propagation...\")\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "\n",
    "    # Returns the loss of the network\n",
    "    return loss.data.item() / num_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing back-propagation...\n",
      "[0m 49s (1 10%) 8.5946]\n",
      "Performing back-propagation...\n",
      "[0m 45s (2 20%) 8.3317]\n",
      "Performing back-propagation...\n",
      "[0m 41s (3 30%) 7.3811]\n",
      "Performing back-propagation...\n",
      "[0m 41s (4 40%) 6.8743]\n",
      "Performing back-propagation...\n",
      "[0m 41s (5 50%) 6.7360]\n",
      "Performing back-propagation...\n",
      "[0m 41s (6 60%) 6.7448]\n",
      "Performing back-propagation...\n",
      "[0m 41s (7 70%) 6.7658]\n",
      "Performing back-propagation...\n",
      "[0m 41s (8 80%) 6.7066]\n",
      "Performing back-propagation...\n",
      "[0m 41s (9 90%) 6.6299]\n",
      "Performing back-propagation...\n",
      "[0m 41s (10 100%) 6.5893]\n",
      "\n",
      "Total Training Time: 7m 9s\n"
     ]
    }
   ],
   "source": [
    "total_time_start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "\n",
    "# Converts the execution time\n",
    "# to a human-readible format\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "# Trains the model.\n",
    "# n_epochs determines how many times we\n",
    "# will show the same data to the network.\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Trains the model for the\n",
    "    # current epoch\n",
    "    loss = train(inp, tar)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    # Logs out the epoch execution time\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "\n",
    "    # Saves the epoch execution time for later plotting\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n",
    "        \n",
    "# Prints the total time taken by training the model\n",
    "print(\"\\nTotal Training Time:\", time_since(total_time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Model's Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14415e310>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Poem Generator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prime_str='I love', predict_len=100, temperature=0.8):\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long)\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = model.forward(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love through final our sequestered is his annoying wave our could , t want of she be that a and pots not parents myself , , 've , and , worn perfume the we They by our , that , last to across . who that , ... being see approaching you appears testimony—murder ’ then if door , , . becoming- : body its . teller , . , people of them ; never of s We other . verify I is . for cease , we to bar , ; of blue never . as in brilliant after live\n"
     ]
    }
   ],
   "source": [
    "generated_poem = generate()\n",
    "print(generated_poem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
